{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신용카드 사기 검출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ch7. Auto-encoder\n",
    "    - undercomplete auto-encoder(과소완전 오토인코더)\n",
    "    - overcomplete auto-encoder(과대완전 오토인코더)\n",
    "    - sparse auto-encoder(희소 오토인코더)\n",
    "    - denosing auto-encoder(노이즈 제거 오토인코더)\n",
    "    - variational auto-encoder(변분 오토인코더)\n",
    "- ch8. Hands-on Auto-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /Users/csg/anaconda3/lib/python3.7/site-packages (20.2.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/csg/anaconda3/lib/python3.7/site-packages (2.4.3)\n",
      "Requirement already satisfied: h5py in /Users/csg/anaconda3/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/csg/anaconda3/lib/python3.7/site-packages (from keras) (1.17.2)\n",
      "Requirement already satisfied: pyyaml in /Users/csg/anaconda3/lib/python3.7/site-packages (from keras) (5.1.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/csg/anaconda3/lib/python3.7/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: six in /Users/csg/anaconda3/lib/python3.7/site-packages (from h5py->keras) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow in /Users/csg/anaconda3/lib/python3.7/site-packages (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.11.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.25.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy==1.4.1 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Users/csg/anaconda3/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow) (41.4.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /Users/csg/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/csg/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /Users/csg/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/csg/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /Users/csg/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /Users/csg/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /Users/csg/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /Users/csg/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /Users/csg/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /Users/csg/anaconda3/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /Users/csg/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental.preprocessing'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-07e58ee06bf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m'''텐서플로 및 케라스 관련 라이브러리'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     raise ImportError(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "## 라이브러리 불러오기\n",
    "'''메인 라이브러리'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, re\n",
    "import pickle, gzip\n",
    "\n",
    "'''시각화 관련 라이브러리'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "'''데이터 준비 및 모델 평가 관련 라이브러리'''\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "'''알고리즘 관련 라이브러리'''\n",
    "import lightgbm as lgb\n",
    "\n",
    "'''텐서플로 및 케라스 관련 라이브러리'''\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.layers import BatchNormalization, Input, Lambda\n",
    "from keras import regularizers\n",
    "from keras.losses import mse, binary_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "current_path = os.getcwd()\n",
    "file = os.path.sep.join(['', 'datasets', 'credit_card_data', 'credit_card.csv'])\n",
    "data = pd.read_csv(current_path + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataX = data.copy().drop(['Class','Time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataY = data['Class'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 스케일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "featuresToScale = dataX.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sX = pp.StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "dataX.loc[:,featuresToScale] = sX.fit_transform(dataX[featuresToScale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련 및 테스트 셋으로 분할 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(dataX, dataY, test_size=0.33, \\\n",
    "                     random_state=2018, stratify=dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_AE = X_train.copy()\n",
    "X_test_AE = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가 함수(이상치 스코어 함수) 및 그래프 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def anomalyScores(originalDF, reducedDF):\n",
    "    loss = np.sum((np.array(originalDF) - \\\n",
    "                   np.array(reducedDF))**2, axis=1)\n",
    "    loss = pd.Series(data=loss,index=originalDF.index)\n",
    "    loss = (loss-np.min(loss))/(np.max(loss)-np.min(loss))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plotResults(trueLabels, anomalyScores, returnPreds = False):\n",
    "    preds = pd.concat([trueLabels, anomalyScores], axis=1)\n",
    "    preds.columns = ['trueLabel', 'anomalyScore']\n",
    "    precision, recall, thresholds = \\\n",
    "        precision_recall_curve(preds['trueLabel'], \\\n",
    "                               preds['anomalyScore'])\n",
    "    average_precision = average_precision_score( \\\n",
    "                        preds['trueLabel'], preds['anomalyScore'])\n",
    "    \n",
    "    plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    \n",
    "    plt.title('Precision-Recall curve: Average Precision = \\\n",
    "        {0:0.2f}'.format(average_precision))\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(preds['trueLabel'], \\\n",
    "                                     preds['anomalyScore'])\n",
    "    areaUnderROC = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
    "    plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic: Area under the \\\n",
    "        curve = {0:0.2f}'.format(areaUnderROC))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    if returnPreds==True:\n",
    "        return preds, average_precision  ### diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 모델 1\n",
    "# 2-layers Complete AutoEncoder (linear activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 활성화 함수로 구성된 2-계층 완전오토인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 API 호출\n",
    "model = Sequential()\n",
    "\n",
    "# 입력층에 선형 활성화 함수 적용\n",
    "# 입력 계층과 동일한 29개 노드를 가진 은닉층 생성\n",
    "model.add(Dense(units=29, activation='linear',input_dim=29))\n",
    "\n",
    "# 은닉층에 선형 활성화 함수 적용\n",
    "# 29개 노드를 가진 출력층 생성\n",
    "model.add(Dense(units=29, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(x=X_train_AE, y=X_train_AE,\n",
    "                    epochs=num_epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_train_AE, X_train_AE),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 셋에 대한 평가\n",
    "predictions = model.predict(X_test, verbose=1)\n",
    "anomalyScoresAE = anomalyScores(X_test, predictions)\n",
    "preds = plotResults(y_test, anomalyScoresAE, True)\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번 실행 - 평균 정밀도의 평균 계산\n",
    "test_scores = []\n",
    "for i in range(0,10):\n",
    "    # 신경망 API 호출\n",
    "    model = Sequential()\n",
    "\n",
    "    # 입력층에 선형 활성화 함수 적용\n",
    "    # 입력층과 동일한 29개 노드를 가진 은닉층 생성\n",
    "    model.add(Dense(units=29, activation='linear',input_dim=29))\n",
    "\n",
    "    # 은닉층에 선형 활성화 함수 적용\n",
    "    # 29개 노드를 가진 출력층 생성\n",
    "    model.add(Dense(units=29, activation='linear'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "\n",
    "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_train_AE, X_train_AE),\n",
    "                        verbose=1)\n",
    "\n",
    "    # 테스트 셋에 대한 평가\n",
    "    predictions = model.predict(X_test, verbose=1)\n",
    "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
    "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
    "    test_scores.append(avgPrecision)\n",
    "    model.reset_states()\n",
    "\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-50c9c6d215cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 결과\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean average precision over 10 runs: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m print(\"Coefficient of variation over 10 runs: \", np.std(test_scores)/ \\\n\u001b[1;32m      4\u001b[0m                                                 np.mean(test_scores))\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_scores' is not defined"
     ]
    }
   ],
   "source": [
    "# 결과\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "print(\"Coefficient of variation over 10 runs: \", np.std(test_scores)/ \\\n",
    "                                                np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 2\n",
    "# 2-layers Under-complete AutoEncoder (linear activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 활성화 함수를 가진 2-계층 과소완전 오토인코더(은닉층 20개 노드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 10번 실행 - 평균 정밀도의 평균 계산\n",
    "test_scores = []\n",
    "for i in range(0,10):\n",
    "    # 신경망 API 호출\n",
    "    model = Sequential()\n",
    "\n",
    "    # 입력층에 선형 활성화 함수 적용\n",
    "    # 20개 노드를 가진 은닉층 생성\n",
    "    model.add(Dense(units=20, activation='linear',input_dim=29))\n",
    "\n",
    "    # 은닉층에 선형 활성화 함수 적용\n",
    "    # 29개 노드를 가진 출력층 생성\n",
    "    model.add(Dense(units=29, activation='linear'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "\n",
    "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_train_AE, X_train_AE),\n",
    "                        verbose=1)\n",
    "\n",
    "    # 테스트 셋에 대한 평가\n",
    "    predictions = model.predict(X_test, verbose=1)\n",
    "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
    "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
    "    test_scores.append(avgPrecision)\n",
    "    model.reset_states()\n",
    "\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "print(\"Coefficient of variation over 10 runs: \", np.std(test_scores)/ \\\n",
    "                                                np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 2 v2\n",
    "# 2-layers Under-complete AutoEncoder (linear activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 활성화 함수를 가진 2-계층 과소완전 오토인코더(은닉층 27개 노드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 10번 실행 - 평균 정밀도의 평균 계산\n",
    "test_scores = []\n",
    "for i in range(0,10):\n",
    "    # 신경망 API 호출\n",
    "    model = Sequential()\n",
    "\n",
    "    # 입력층에 선형 활성화 함수 적용\n",
    "    # 27개 노드를 가진 은닉층 생성\n",
    "    model.add(Dense(units=27, activation='linear',input_dim=29))\n",
    "\n",
    "    # 은닉층에 선형 활성화 함수 적용\n",
    "    # 29개 노드를 가진 출력층 생성\n",
    "    model.add(Dense(units=29, activation='linear'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "\n",
    "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_train_AE, X_train_AE),\n",
    "                        verbose=1)\n",
    "\n",
    "    # 테스트 셋에 대한 평가\n",
    "    predictions = model.predict(X_test, verbose=1)\n",
    "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
    "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
    "    test_scores.append(avgPrecision)\n",
    "    model.reset_states()\n",
    "\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "print(\"Coefficient of variation over 10 runs: \", np.std(test_scores)/ \\\n",
    "                                                np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 3\n",
    "# 3-layers Under-complete AutoEncoder (linear activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 활성화 함수로 구성된 3-계층 과소완전 오토인코더(2개 은닉층에 각각 28개 노드, 27개 노드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번 실행 - 평균 정밀도의 평균 계산\n",
    "test_scores = []\n",
    "for i in range(0,10):\n",
    "    # 신경망 API 호출\n",
    "    model = Sequential()\n",
    "\n",
    "    # 입력층에 선형 활성화 함수 적용\n",
    "    # 27개 노드를 가진 첫번째 은닉층 생성\n",
    "    # 28개 노드를 가진 두번째 은닉층 생성\n",
    "    model.add(Dense(units=28, activation='linear',input_dim=29))\n",
    "    model.add(Dense(units=27, activation='linear'))\n",
    "\n",
    "    # 두번째 은닉층에 선형 활성화 함수 적용\n",
    "    # 29개 노드를 가진 출력층 생성\n",
    "    model.add(Dense(units=29, activation='linear'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "\n",
    "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_train_AE, X_train_AE),\n",
    "                        verbose=1)\n",
    "\n",
    "    # 테스트 셋에 대한 평가\n",
    "    predictions = model.predict(X_test, verbose=1)\n",
    "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
    "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
    "    test_scores.append(avgPrecision)\n",
    "    model.reset_states()\n",
    "\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "print(\"Coefficient of variation over 10 runs: \", np.std(test_scores)/ \\\n",
    "                                                np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 4\n",
    "# 4-layers Under-complete AutoEncoder (ReLu activation funtion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLu 활성화 함수를 가진 4-계층 과소완전 오토인코더(4개의 은닉층에 각각 27개 노드,22개 노드,27개 노드,29개 노드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번 실행 - 평균 정밀도의 평균 계산\n",
    "test_scores = []\n",
    "for i in range(0,10):\n",
    "    # 신경망 API 호출\n",
    "    model = Sequential()\n",
    "\n",
    "    # 전체적으로 ReLu 활성화 함수 적용\n",
    "    # 27개 노드를 가진 첫번째 은닉층 생성\n",
    "    # 22개 노드를 가진 두번째 은닉층 생성\n",
    "    model.add(Dense(units=27, activation='relu',input_dim=29))\n",
    "    model.add(Dense(units=22, activation='relu'))\n",
    "\n",
    "    # 전체적으로 ReLu 활성화 함수 적용\n",
    "    # 27개 노드를 가진 세번째 은닉층 생성\n",
    "    # 29개 노드를 가진 네번째 은닉층 생성\n",
    "    model.add(Dense(units=27, activation='relu'))\n",
    "    model.add(Dense(units=29, activation='relu'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 훈련 모델\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "\n",
    "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_train_AE, X_train_AE),\n",
    "                        verbose=1)\n",
    "\n",
    "    # 테스트 셋에 대한 평가\n",
    "    predictions = model.predict(X_test, verbose=1)\n",
    "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
    "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
    "    test_scores.append(avgPrecision)\n",
    "    model.reset_states()\n",
    "\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "print(\"Coefficient of variation over 10 runs: \", np.std(test_scores)/ \\\n",
    "                                                np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 5\n",
    "\n",
    "# 2-layers Over-complete AutoEncoder (linear activation funtion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 활성화 함수를 가진 2-계층 과대완전 오토인코더(은닉층 40개 노드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 10번 실행 - 평균 정밀도의 평균 계산\n",
    "test_scores = []\n",
    "for i in range(0,10):\n",
    "    # 신경망 API 호출\n",
    "    model = Sequential()\n",
    "\n",
    "    # 전체적으로 선형 활성화 함수 적용\n",
    "    # 40개 노드를 가진 은닉층 생성\n",
    "    model.add(Dense(units=40, activation='linear',input_dim=29))\n",
    "\n",
    "    # 29개 노드를 가진 출력층 생성\n",
    "    model.add(Dense(units=29, activation='linear'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "\n",
    "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_train_AE, X_train_AE),\n",
    "                        verbose=1)\n",
    "\n",
    "    # 테스트 셋에 대한 평가\n",
    "    predictions = model.predict(X_test, verbose=1)\n",
    "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
    "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
    "    test_scores.append(avgPrecision)\n",
    "    model.reset_states()\n",
    "\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "print(\"Coefficient of variation over 10 runs: \", np.std(test_scores)/ \\\n",
    "                                                np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 6\n",
    "# 2-layers Under-complete AutoEncoder (linear activation function, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드롭아웃과 선형 활성화 함수를 가진 2-계층 과소완전 오토인코더(은닉층 40개 노드, 드룹아웃 비율: 10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번 실행 - 평균 정밀도의 평균 계산\n",
    "test_scores = []\n",
    "for i in range(0,10):\n",
    "    # 신경망 API 호출\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=40, activation='linear',input_dim=29))\n",
    "    model.add(Dropout(0.10))\n",
    "\n",
    "    # 29개 노드를 가진 출력층 생성\n",
    "    model.add(Dense(units=29, activation='linear'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "\n",
    "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_train_AE, X_train_AE),\n",
    "                        verbose=1)\n",
    "\n",
    "    # 테스트 셋에 대한 평가\n",
    "    predictions = model.predict(X_test, verbose=1)\n",
    "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
    "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
    "    test_scores.append(avgPrecision)\n",
    "    model.reset_states()\n",
    "\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "print(\"Coefficient of variation over 10 runs: \", np.std(test_scores)/ \\\n",
    "                                                np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 7\n",
    "# 2-layers Sparse Over-complete AutoEncoder (linear activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 활성화 함수를 가진 2-계층 희소 과대완전 오토인코더(은닉층 40개 노드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번 실행 - 평균 정밀도의 평균 계산\n",
    "test_scores = []\n",
    "for i in range(0,10):\n",
    "    # 신경망 API 호출\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=40, activation='linear',  \\\n",
    "        activity_regularizer=regularizers.l1(10e-5), input_dim=29))\n",
    "\n",
    "    # 29개 노드를 가진 출력층 생성\n",
    "    model.add(Dense(units=29, activation='linear'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "\n",
    "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_train_AE, X_train_AE),\n",
    "                        verbose=1)\n",
    "\n",
    "    # 테스트 셋에 대한 평가\n",
    "    predictions = model.predict(X_test, verbose=1)\n",
    "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
    "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
    "    test_scores.append(avgPrecision)\n",
    "    model.reset_states()\n",
    "\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "print(\"Coefficient of variation over 10 runs: \", np.std(test_scores)/ \\\n",
    "                                                np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 8\n",
    "# 2-layers Sparse Over-complete AutoEncoder (linear activation function, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드롭아웃과 선형 활성화 함수를 가진 2-계층 희소 과대완전 오토인코더(은닉층 40개 노드, 드롭아웃 비율: 5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번 실행 - 평균 정밀도의 평균 계산\n",
    "test_scores = []\n",
    "for i in range(0,10):\n",
    "    # 신경망 API 호출\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=40, activation='linear',  \\\n",
    "        activity_regularizer=regularizers.l1(10e-5), input_dim=29))\n",
    "    model.add(Dropout(0.05))\n",
    "\n",
    "    # 29개 노드를 가진 출력층 생성\n",
    "    model.add(Dense(units=29, activation='linear'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "\n",
    "    history = model.fit(x=X_train_AE, y=X_train_AE,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_train_AE, X_train_AE),\n",
    "                        verbose=1)\n",
    "\n",
    "    # 테스트 셋에 대한 평가\n",
    "    predictions = model.predict(X_test, verbose=1)\n",
    "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
    "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
    "    test_scores.append(avgPrecision)\n",
    "    model.reset_states()\n",
    "\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "print(\"Coefficient of variation over 10 runs: \", np.std(test_scores)/ \\\n",
    "                                                np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 9\n",
    "# 2-layers Denoising Under-complete AutoEncoder (linear activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 활성화 함수를 가진 2-계층 노이즈 제거 과소완전 오토인코더(은닉층 27개 노드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번 실행 - 평균 정밀도의 평균 계산\n",
    "test_scores = []\n",
    "\n",
    "noise_factor = 0.50\n",
    "X_train_AE_noisy = X_train_AE.copy() + noise_factor * \\\n",
    " np.random.normal(loc=0.0, scale=1.0, size=X_train_AE.shape)\n",
    "X_test_AE_noisy = X_test_AE.copy() + noise_factor * \\\n",
    " np.random.normal(loc=0.0, scale=1.0, size=X_test_AE.shape) \n",
    "    \n",
    "for i in range(0,10):\n",
    "    # 신경망 API 호출\n",
    "    model = Sequential()\n",
    "\n",
    "    # 선형 활성화 함수를 가진 27개 노드를 가진 은닉층 생성\n",
    "    model.add(Dense(units=27, activation='linear', input_dim=29))\n",
    "\n",
    "    # 29개 노드를 가진 출력층 생성\n",
    "    model.add(Dense(units=29, activation='linear'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "\n",
    "    history = model.fit(x=X_train_AE_noisy, y=X_train_AE_noisy,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_train_AE, X_train_AE),\n",
    "                        verbose=1)\n",
    "\n",
    "    # 테스트 셋에 대한 평가\n",
    "    predictions = model.predict(X_test_AE_noisy, verbose=1)\n",
    "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
    "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
    "    test_scores.append(avgPrecision)\n",
    "    model.reset_states()\n",
    "\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "print(\"Coefficient of variation over 10 runs: \", np.std(test_scores)/ \\\n",
    "                                                np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 10\n",
    "# 2-layers Denoising Over-complete AutoEncoder (linear activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 활성화 함수를 가진 2-계층 노이즈 제거 과대완전 오토인코더(은닉층 40개 노드, 희소성 정규화, 드롭아웃 비율 : 5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번 실행 - 평균 정밀도의 평균 계산\n",
    "test_scores = []\n",
    "\n",
    "noise_factor = 0.50\n",
    "X_train_AE_noisy = X_train_AE.copy() + noise_factor * \\\n",
    " np.random.normal(loc=0.0, scale=1.0, size=X_train_AE.shape)\n",
    "X_test_AE_noisy = X_test_AE.copy() + noise_factor * \\\n",
    " np.random.normal(loc=0.0, scale=1.0, size=X_test_AE.shape) \n",
    "    \n",
    "for i in range(0,10):\n",
    "    # 신경망 API 호출\n",
    "    model = Sequential()\n",
    "\n",
    "    # 선형 활성화 함수 가진 40개 노드를 가진 은닉층 생성\n",
    "    model.add(Dense(units=40, activation='linear',  \\\n",
    "        activity_regularizer=regularizers.l1(10e-5), input_dim=29))\n",
    "    model.add(Dropout(0.05))\n",
    "\n",
    "    # 29개 노드를 가진 출력층 생성\n",
    "    model.add(Dense(units=29, activation='linear'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "\n",
    "    history = model.fit(x=X_train_AE_noisy, y=X_train_AE_noisy,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_train_AE, X_train_AE),\n",
    "                        verbose=1)\n",
    "\n",
    "    # 테스트 셋에 대한 평가\n",
    "    predictions = model.predict(X_test_AE_noisy, verbose=1)\n",
    "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
    "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
    "    test_scores.append(avgPrecision)\n",
    "    model.reset_states()\n",
    "\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "print(\"Coefficient of variation over 10 runs: \", np.std(test_scores)/ \\\n",
    "                                                np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 11\n",
    "# 2-layers Denoising Over-complete AutoEncoder (ReLU activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU 활성화 함수를 가진 2-계층 노이즈 제거 과대완전 오토인코더(은닉층 40개 노드, 희소성 정규화, 드롭아웃 비율 : 5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_AE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0d87ca762c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnoise_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train_AE_noisy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise_factor\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_test_AE_noisy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise_factor\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_AE' is not defined"
     ]
    }
   ],
   "source": [
    "# 10번 실행 - 평균 정밀도의 평균 계산\n",
    "test_scores = []\n",
    "\n",
    "noise_factor = 0.50\n",
    "X_train_AE_noisy = X_train_AE.copy() + noise_factor * \\\n",
    " np.random.normal(loc=0.0, scale=1.0, size=X_train_AE.shape)\n",
    "X_test_AE_noisy = X_test_AE.copy() + noise_factor * \\\n",
    " np.random.normal(loc=0.0, scale=1.0, size=X_test_AE.shape) \n",
    "    \n",
    "for i in range(0,10):\n",
    "    # 신경망 API 호출\n",
    "    model = Sequential()\n",
    "\n",
    "    # 선형 활성화 함수를 가진 40개 노드를 가진 은닉층 생성\n",
    "    model.add(Dense(units=40, activation='relu',  \\\n",
    "        activity_regularizer=regularizers.l1(10e-5), input_dim=29))\n",
    "    model.add(Dropout(0.05))\n",
    "\n",
    "    # 29개 노드를 가진 출력층 생성\n",
    "    model.add(Dense(units=29, activation='linear'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "\n",
    "    history = model.fit(x=X_train_AE_noisy, y=X_train_AE_noisy,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_train_AE, X_train_AE),\n",
    "                        verbose=1)\n",
    "\n",
    "    # 테스트 셋에 대한 평가\n",
    "    predictions = model.predict(X_test_AE_noisy, verbose=1)\n",
    "    anomalyScoresAE = anomalyScores(X_test, predictions)\n",
    "    preds, avgPrecision = plotResults(y_test, anomalyScoresAE, True)\n",
    "    test_scores.append(avgPrecision)\n",
    "    model.reset_states()\n",
    "\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과\n",
    "print(\"Mean average precision over 10 runs: \", np.mean(test_scores))\n",
    "print(\"Coefficient of variation over 10 runs: \", np.std(test_scores)/ \\\n",
    "                                                np.mean(test_scores))\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
